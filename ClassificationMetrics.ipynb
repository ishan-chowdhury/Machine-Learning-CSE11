{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSPJfzqST7tG7Yd0DKdKPZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishan-chowdhury/Machine-Learning-CSE11/blob/main/ClassificationMetrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E0VnqKr4DCGY"
      },
      "outputs": [],
      "source": [
        "# Accuracy measures the overall correctness of the model with the classifier. It is used in balanced dataset.\n",
        "# Precision measures how many predicted positives are actually correct.\n",
        "# It is used in spam detection, fraud detection, medical diagnosis, where false positives should be less\n",
        "# Recall measures how many actual positives are correctly identified.\n",
        "# If the recall is very high then the false negatives are very less, used in critical systems.\n",
        "# F1-Score = When the dataset is imbalanced then we use the f1-score to balance the preicision and the recall to a single score.\n",
        "# It is the harmonic mean of the precision and the recall.\n",
        "# Specificity (True Negative Rate) - It measures how well the model identifies negative cases."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "7Yig1h2sDVRO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQpk55AtDgAL",
        "outputId": "b1d3e013-b28e-4631-d240-dead12ff2291"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.11.12)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = iris.data.features\n",
        "y = iris.data.targets\n",
        "\n",
        "# metadata\n",
        "print(iris.metadata)\n",
        "\n",
        "# variable information\n",
        "print(iris.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOHfwMuhDbhQ",
        "outputId": "6218990d-4668-445a-8a0b-92374f1b8869"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
            "           name     role         type demographic  \\\n",
            "0  sepal length  Feature   Continuous        None   \n",
            "1   sepal width  Feature   Continuous        None   \n",
            "2  petal length  Feature   Continuous        None   \n",
            "3   petal width  Feature   Continuous        None   \n",
            "4         class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                               None    cm             no  \n",
            "1                                               None    cm             no  \n",
            "2                                               None    cm             no  \n",
            "3                                               None    cm             no  \n",
            "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(iris.data.features)\n",
        "print(\"The shape of the dataset\")\n",
        "print(df.shape)\n",
        "\n",
        "X  = pd.DataFrame(iris.data.features)\n",
        "y = pd.DataFrame(iris.data.targets)\n",
        "\n",
        "print(\"Shape of Input and Label\")\n",
        "print(X.shape , y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsoLrX_NDeZQ",
        "outputId": "dcd2a92f-3470-4a7a-d84b-5d93ad51c087"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the dataset\n",
            "(150, 4)\n",
            "Shape of Input and Label\n",
            "(150, 4) (150, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cXd-N7r-DlOa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "ypred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "7D1v-ZeYDoGE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "accuracy = accuracy_score(y_test, ypred)\n",
        "precision = precision_score(y_test, ypred, average='weighted')\n",
        "recall = recall_score(y_test, ypred, average='weighted')\n",
        "f1 = f1_score(y_test, ypred, average='weighted')\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH7k0uJ9DvaB",
        "outputId": "87e7b8ab-5e26-4257-835c-4a603e9c8eea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First the classification metircs are true positive true negative false positive false negative\n",
        "# True postive means that we have actual and predicted values as same\n",
        "# True negaitve means that we have the actual value is true (1) and the negative value is (0) This is when we have the actual value is say spam but we have predicted it as not spam.\n",
        "# False positive means that actual value is (0) and the predicted value is (1) so we have predicted as spam but it is actually not spam\n",
        "# False negative means that actual value is positive (1) but we predicted (0) so it is spam but we said not spam.\n",
        "\n",
        "\n",
        "\n",
        "# The first metric is of course accuracy which is just the addition of the correct metrics tp and tn divided by sum of all of them. Used to find the overall accurcy of the model\n",
        "# The next metric is precision which tracks the actual predictions TP / FP + TP\n",
        "# The next metric is recall which tracks the false predictions TP / TP  + FN\n",
        "# F1-Score is just 2 * p * r / p + r\n"
      ],
      "metadata": {
        "id": "Ty9uAqooDxyc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us do the multi class confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "#For Iris-Setosa\n",
        "print(y.value_counts())\n",
        "\n",
        "#First find the predictions#\n",
        "print(ypred)\n",
        "true_Positive = 0\n",
        "true_Negative = 0\n",
        "false_Positive = 0\n",
        "false_Negative = 0\n",
        "\n",
        "for i in range(len(ypred)):\n",
        "    actual = y_test.iloc[i]['class']\n",
        "    predicted = ypred[i]\n",
        "\n",
        "    if actual == 'Iris-setosa' and predicted == 'Iris-setosa':\n",
        "        true_Positive += 1\n",
        "    elif actual != 'Iris-setosa' and predicted == 'Iris-setosa':\n",
        "        false_Positive += 1\n",
        "    elif actual == 'Iris-setosa' and predicted != 'Iris-setosa':\n",
        "        false_Negative += 1\n",
        "    else:\n",
        "        true_Negative += 1\n",
        "\n",
        "print(\"True Positive:\", true_Positive)\n",
        "print(\"True Negative:\", true_Negative)\n",
        "print(\"False Positive:\", false_Positive)\n",
        "print(\"False Negative:\", false_Negative)\n",
        "\n",
        "\n",
        "accuracy_score = (true_Positive + true_Negative) / (true_Positive + true_Negative + false_Positive + false_Negative)\n",
        "precision_score = true_Positive / (true_Positive + false_Positive)\n",
        "recall_score = true_Positive / (true_Positive + false_Negative)\n",
        "f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
        "print(\"Accuracy:\", accuracy_score)\n",
        "print(\"Precision:\", precision_score)\n",
        "print(\"Recall:\", recall_score)\n",
        "print(\"F1-score:\", f1_score)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiSNWKW4Fizr",
        "outputId": "e63e6077-5060-4785-a9f2-871e9d8b6b33"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class          \n",
            "Iris-setosa        50\n",
            "Iris-versicolor    50\n",
            "Iris-virginica     50\n",
            "Name: count, dtype: int64\n",
            "['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
            " 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
            " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
            " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
            " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
            " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
            " 'Iris-setosa' 'Iris-setosa']\n",
            "True Positive: 10\n",
            "True Negative: 20\n",
            "False Positive: 0\n",
            "False Negative: 0\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For Iris-viriginica\n",
        "\n",
        "true_Positive = 0\n",
        "true_Negative = 0\n",
        "false_Positive = 0\n",
        "false_Negative = 0\n",
        "\n",
        "for i in range(len(ypred)):\n",
        "    actual = y_test.iloc[i]['class']        # y_test['class'].values\n",
        "    predicted_label = ypred[i]  # ypred\n",
        "\n",
        "    if actual == 'Iris-virginica' and predicted_label == 'Iris-virginica':\n",
        "        true_Positive += 1\n",
        "\n",
        "    elif actual != 'Iris-virginica' and predicted_label == 'Iris-virginica':\n",
        "        false_Positive += 1\n",
        "\n",
        "    elif actual == 'Iris-virginica' and predicted_label != 'Iris-virginica':\n",
        "        false_Negative += 1\n",
        "\n",
        "    else:\n",
        "        true_Negative += 1\n",
        "\n",
        "print(\"Virginica → True Positive:\", true_Positive)\n",
        "print(\"Virginica → True Negative:\", true_Negative)\n",
        "print(\"Virginica → False Positive:\", false_Positive)\n",
        "print(\"Virginica → False Negative:\", false_Negative)\n",
        "\n",
        "\n",
        "\n",
        "accuracy_score = (true_Positive + true_Negative) / (true_Positive + true_Negative + false_Positive + false_Negative)\n",
        "precision_score = true_Positive / (true_Positive + false_Positive)\n",
        "recall_score = true_Positive / (true_Positive + false_Negative)\n",
        "f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
        "print(\"Accuracy:\", accuracy_score)\n",
        "print(\"Precision:\", precision_score)\n",
        "print(\"Recall:\", recall_score)\n",
        "print(\"F1-score:\", f1_score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANp-pK8SIR9D",
        "outputId": "b9f53f99-f906-493f-8b6a-44c805f76ead"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Virginica → True Positive: 11\n",
            "Virginica → True Negative: 19\n",
            "Virginica → False Positive: 0\n",
            "Virginica → False Negative: 0\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_Positive = 0\n",
        "true_Negative = 0\n",
        "false_Positive = 0\n",
        "false_Negative = 0\n",
        "\n",
        "for i in range(len(ypred)):\n",
        "    actual_label = y_test.iloc[i]['class']        # y_test['class'].values\n",
        "    predicted_label = ypred[i]  # ypred\n",
        "\n",
        "    if actual_label == 'Iris-versicolor' and predicted_label == 'Iris-versicolor':\n",
        "        true_Positive += 1\n",
        "\n",
        "    elif actual_label != 'Iris-versicolor' and predicted_label == 'Iris-versicolor':\n",
        "        false_Positive += 1\n",
        "\n",
        "    elif actual_label == 'Iris-versicolor' and predicted_label != 'Iris-versicolor':\n",
        "        false_Negative += 1\n",
        "\n",
        "    else:\n",
        "        true_Negative += 1\n",
        "\n",
        "print(\"Versicolor → True Positive:\", true_Positive)\n",
        "print(\"Versicolor → True Negative:\", true_Negative)\n",
        "print(\"Versicolor → False Positive:\", false_Positive)\n",
        "print(\"Versicolor → False Negative:\", false_Negative)\n",
        "\n",
        "\n",
        "\n",
        "accuracy_score = (true_Positive + true_Negative) / (true_Positive + true_Negative + false_Positive + false_Negative)\n",
        "precision_score = true_Positive / (true_Positive + false_Positive)\n",
        "recall_score = true_Positive / (true_Positive + false_Negative)\n",
        "f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
        "print(\"Accuracy:\", accuracy_score)\n",
        "print(\"Precision:\", precision_score)\n",
        "print(\"Recall:\", recall_score)\n",
        "print(\"F1-score:\", f1_score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY146cR1JrAn",
        "outputId": "9b027726-43f3-458c-e5c2-2f9c0ff3d1d7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versicolor → True Positive: 9\n",
            "Versicolor → True Negative: 21\n",
            "Versicolor → False Positive: 0\n",
            "Versicolor → False Negative: 0\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
        "\n",
        "# Initialize confusion counts\n",
        "TP = {cls: 0 for cls in classes}\n",
        "FP = {cls: 0 for cls in classes}\n",
        "FN = {cls: 0 for cls in classes}\n",
        "TN = {cls: 0 for cls in classes}\n",
        "\n",
        "for i in range(len(predicted)):\n",
        "    actual_label = actual[i]\n",
        "    predicted_label = predicted[i]\n",
        "\n",
        "    for cls in classes:\n",
        "        if actual_label == cls and predicted_label == cls:\n",
        "            TP[cls] += 1\n",
        "        elif actual_label != cls and predicted_label == cls:\n",
        "            FP[cls] += 1\n",
        "        elif actual_label == cls and predicted_label != cls:\n",
        "            FN[cls] += 1\n",
        "        else:\n",
        "            TN[cls] += 1\n",
        "\n",
        "# Print results\n",
        "for cls in classes:\n",
        "    print(f\"\\nClass: {cls}\")\n",
        "    print(\"TP:\", TP[cls])\n",
        "    print(\"FP:\", FP[cls])\n",
        "    print(\"FN:\", FN[cls])\n",
        "    print(\"TN:\", TN[cls])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKdoUkEJKA3f",
        "outputId": "1748e595-57ee-46b4-e096-1b46c30845e7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class: Iris-setosa\n",
            "TP: 0\n",
            "FP: 0\n",
            "FN: 0\n",
            "TN: 11\n",
            "\n",
            "Class: Iris-versicolor\n",
            "TP: 0\n",
            "FP: 0\n",
            "FN: 0\n",
            "TN: 11\n",
            "\n",
            "Class: Iris-virginica\n",
            "TP: 0\n",
            "FP: 0\n",
            "FN: 0\n",
            "TN: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtA-dhCUKxfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}